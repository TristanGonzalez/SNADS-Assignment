network::set.vertex.attribute(net, "userid", value = final_nodes$userid)
# Set other vertex attributes
network::set.vertex.attribute(net, "user_reported_location", value = final_nodes$user_reported_location)
network::set.vertex.attribute(net, "follower_count", value = final_nodes$follower_count)
network::set.vertex.attribute(net, "following_count", value = final_nodes$following_count)
network::set.vertex.attribute(net, "account_language", value = final_nodes$account_language)
network::set.vertex.attribute(net, "hashtag_category", value = final_nodes$hashtag_category)
network::set.vertex.attribute(net, "hashtag", value = final_nodes$hashtags)
m0 <- ergm::ergm(net ~ edges)
summary(m0)
# Model with edges and exogenous term
m1 <- ergm::ergm(net ~ edges + nodematch("hashtag_category"))
m2 <- ergm::ergm(net ~ edges + nodematch("hashtag_category") + nodeicov("follower_count"))
# Model with edges and mutual good!
m3 <- ergm::ergm(net ~ edges + mutual)
summary(m3)
ergm::mcmc.diagnostics(m3)
#look at what value is meaningful for the indegree
max_in_degree <-sna::degree(net, cmode = "indegree")
print(table(max_in_degree))
m5 <- ergm::ergm(net ~ edges + gwin)
m5 <- ergm::ergm(net ~ edges + gwidegree(.5,fixed=T))
m5 <- ergm::ergm(net ~ edges + gwidegree(.5,fixed=T),
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + nodematch("hashtag_category") + nodeicov("follower_count") + mutual + idegree(d=7) + odegree(2),
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6,))
#runs
final <- ergm::ergm(net ~ edges + nodeicov("follower_count") + mutual + idegree(d=7) + odegree(2),
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6,))
knitr::opts_chunk$set(echo = TRUE)
df_raw <- readr::read_csv("spain_082019_tweets_csv_hashed.csv")
head(df_raw)
df <- subset(df_raw, select=c(userid, user_reported_location, follower_count, following_count, account_creation_date, account_language, tweet_language, quote_count, reply_count, like_count, retweet_count, hashtags))
#create list with seperate hashtags and subsequently clean them
df$hashtags <- strsplit(df$hashtags, split = "', '")
df$hashtags <- lapply(df$hashtags, function(vector) {
gsub("\\[|\\]|'", "", vector)})  # Clean brackets and quotes
df
mode <- function(x) {
# Return NA if the vector is empty
if (length(x) == 0) {
return(NA)
}
# Create a frequency table
freq_table <- table(x)
# Find the most frequent value(s)
max_freq <- max(freq_table)
modes <- names(freq_table[freq_table == max_freq])
# Return the first mode (or modify this to return all modes if desired)
return(modes[1])
}
(user_hashtags)
mode <- function(x) {
# Return NA if the vector is empty
if (length(x) == 0) {
return(NA)
}
# Create a frequency table
freq_table <- table(x)
# Find the most frequent value(s)
max_freq <- max(freq_table)
modes <- names(freq_table[freq_table == max_freq])
# Return the first mode (or modify this to return all modes if desired)
return(modes[1])
}
(user_hashtags)
mode <- function(x) {
# Return NA if the vector is empty
if (length(x) == 0) {
return(NA)
}
# Create a frequency table
freq_table <- table(x)
# Find the most frequent value(s)
max_freq <- max(freq_table)
modes <- names(freq_table[freq_table == max_freq])
# Return the first mode (or modify this to return all modes if desired)
return(modes[1])
}
(user_hashtags)
knitr::opts_chunk$set(echo = TRUE)
df_raw <- readr::read_csv("spain_082019_tweets_csv_hashed.csv")
head(df_raw)
df <- subset(df_raw, select=c(userid, user_reported_location, follower_count, following_count, account_creation_date, account_language, tweet_language, quote_count, reply_count, like_count, retweet_count, hashtags))
#create list with seperate hashtags and subsequently clean them
df$hashtags <- strsplit(df$hashtags, split = "', '")
df$hashtags <- lapply(df$hashtags, function(vector) {
gsub("\\[|\\]|'", "", vector)})  # Clean brackets and quotes
df
mode <- function(x) {
# Return NA if the vector is empty
if (length(x) == 0) {
return(NA)
}
# Create a frequency table
freq_table <- table(x)
# Find the most frequent value(s)
max_freq <- max(freq_table)
modes <- names(freq_table[freq_table == max_freq])
# Return the first mode (or modify this to return all modes if desired)
return(modes[1])
}
(user_hashtags)
mode <- function(x) {
# Return NA if the vector is empty
if (length(x) == 0) {
return(NA)
}
# Create a frequency table
freq_table <- table(x)
# Find the most frequent value(s)
max_freq <- max(freq_table)
modes <- names(freq_table[freq_table == max_freq])
# Return the first mode (or modify this to return all modes if desired)
return(modes[1])
}
user_hashtags <- data.frame(
userid = rep(df$userid, lengths(df$hashtags)),
hashtags = unlist(df$hashtags)
)
user_mode_hashtags <- aggregate(hashtags ~ userid, data= user_hashtags, FUN= mode)
user_mode_hashtags
# Standardize by converting to lowercase
user_mode_hashtags$hashtags <- tolower(user_mode_hashtags$hashtags)
# Manual standardization for specific cases
user_mode_hashtags$hashtags[user_mode_hashtags$hashtags %in% c("sánchezseesconde", "sanchezseesconde")] <- "sanchezseesconde"
user_mode_hashtags$hashtags[user_mode_hashtags$hashtags %in% c("stopokupas", "stopokupas")] <- "stopokupas"
user_mode_hashtags$hashtags[user_mode_hashtags$hashtags %in% c("sánchezmentiroso", "sanchezmentiroso")] <- "sanchezmentiroso"
user_mode_hashtags$hashtags[user_mode_hashtags$hashtags %in% c("stopsoe", "stopsanchez", "sto")] <- "stopsanchez"
# Standardize by converting to lowercase
user_mode_hashtags$hashtags <- tolower(user_mode_hashtags$hashtags)
# Manual standardization for specific cases
user_mode_hashtags$hashtags[user_mode_hashtags$hashtags %in% c("sánchezseesconde", "sanchezseesconde")] <- "sanchezseesconde"
user_mode_hashtags$hashtags[user_mode_hashtags$hashtags %in% c("stopokupas", "stopokupas")] <- "stopokupas"
user_mode_hashtags$hashtags[user_mode_hashtags$hashtags %in% c("sánchezmentiroso", "sanchezmentiroso")] <- "sanchezmentiroso"
user_mode_hashtags$hashtags[user_mode_hashtags$hashtags %in% c("stopsoe", "stopsanchez", "sto")] <- "stopsanchez"
# Define a function to categorize hashtags
categorize_hashtag <- function(hashtag) {
if (hashtag %in% c("sanchezseesconde", "sanchezmentiroso", "despídetedesánchez",
"elsanchismoesruina", "decretazosánchez", "decretazotegi",
"stopokupas", "stopsanchez", "stopsoe")) {
return("Anti-Sanchez/PSOE")
} else if (hashtag %in% c("casadoa3n", "casadoconespaña", "casadoconfjl",
"objetivocasado", "pablocasadoeh", "ventealpp",
"másppmáscultura", "másppmásigualdad",
"másppmenosimpuestos", "valorseguro")) {
return("Pro-PP/Casado")
} else if (hashtag %in% c("prisiónpermanenterevisable", "democraciarealya",
"libertadencataluña", "quenotelacuelen",
"viveponiente", "republicaadelante")) {
return("Civic/General Issues")
} else if (hashtag %in% c("l6ndebatea7", "debatertve", "micasaelecciones",
"lavozasaltos3", "lavozsemifinal",
"éraseunarvezcasado", "juegodeescaños", "felizjueves")) {
return("Media and Events")
} else if (hashtag %in% c("pedroselofunde", "stopsanchez", "stopokupas",
"decretazosánchez", "elsanchismoesruina", "sanchezmentiroso",
"ghdúo", "lavozasaltos3", "micasaelecciones", "eldebatelv")) {
return("Anti-Socialist Campaign")
} else if (hashtag %in% c("porlaconciliaciónreal", "nohablamoshacemos", "falconviajes",
"elppeseconomía", "assassinscreed", "agua")) {
return("Social and Economic Topics")
} else if (hashtag %in% c("niobreroniespañol", "rumbournasarv", "miprimerTweet",
"túaboadillayoamajadahonda", "vuelvezapatero",
"nuevovídeodelpsoe")) {
return("Cultural/Personal Topics")
} else if (hashtag %in% c("juegodetronos", "endirecto", "felizjueves",
"concalma", "deseo", "ghdúo9a")) {
return("Lifestyle and Fun")
} else {
return("Uncategorized")
}
}
# Apply the function to create a new column
(user_mode_hashtags)
user_mode_hashtags$hashtag_category <- sapply(user_mode_hashtags$hashtags, categorize_hashtag)
table(user_mode_hashtags$hashtag_category)
sum(is.na(user_mode_hashtags$hashtag_category))
(user_mode_hashtags)
#group by user id and create aggregates for
mode2 <- function(x) {
x <- x[!is.na(x)] # Remove NA values
if (length(x) == 0) return(NA) # Return NA for empty groups
freq_table <- table(x)
names(freq_table)[which.max(freq_table)]
}
users <- unique(df$userid)
user_location <- aggregate(user_reported_location ~ userid, data=df, FUN = mode2)
user_follower <- aggregate(follower_count ~ userid, data=df, FUN = mode2)
user_following <- aggregate(following_count ~ userid, data=df, FUN = mode2)
user_acc_creation <- aggregate(account_creation_date ~ userid, data=df, FUN = mode2)
user_acc_language <- aggregate(account_language ~ userid, data=df, FUN = mode2)
user_tweet_language <- aggregate(tweet_language ~ userid, data=df, FUN = mode2)
aggregated_stats <- aggregate(cbind(quote_count, reply_count, like_count, retweet_count) ~ userid, data=df, FUN = mean)
aggregated_stats
# Create a named vector for the standardized mapping
location_map <- c(
"Islas Canarias, España" = "Canary Islands, Spain",
"Community of Madrid, Spain" = "Madrid, Spain",
"Burgos, España" = "Burgos, Spain",
"Madrid, Spain" = "Madrid, Spain",
"Alicante, Spain" = "Alicante, Spain",
"El Escorial, España" = "El Escorial, Spain",
"Seville, Spain" = "Seville, Spain",
"Madrid" = "Madrid, Spain",
"Córdoba, España" = "Córdoba, Spain",
"Rome, Lazio" = "Rome, Italy",
"España" = "Spain",
"Cantabria, España" = "Cantabria, Spain",
"Valencia, Spain" = "Valencia, Spain",
"Madrid, Comunidad de Madrid" = "Madrid, Spain",
"Soto del Real, España" = "Soto del Real, Spain",
"Fuenlabrada, Spain" = "Fuenlabrada, Spain",
"Barcelona, Spain" = "Barcelona, Spain",
"Barcelona, España" = "Barcelona, Spain",
"Segovia, Spain" = "Segovia, Spain",
"Ribadeo, Spain" = "Ribadeo, Spain",
"Getafe, España" = "Getafe, Spain",
"Santander" = "Santander, Spain",
"Comunidad de Madrid, España" = "Madrid, Spain",
"Cádiz-Sevilla" = "Cádiz, Spain",
"Spain" = "Spain",
"Toledo, España" = "Toledo, Spain",
"Pontevedra, España" = "Pontevedra, Spain",
"Granada, Spain" = "Granada, Spain",
"Zaragoza, España" = "Zaragoza, Spain",
"Principado de Asturias, España" = "Asturias, Spain",
"Cáceres, España" = "Cáceres, Spain",
"Lituania" = "Lithuania",
"Málaga, España" = "Málaga, Spain",
"Sevilla" = "Seville, Spain",
"Sevilla, España" = "Seville, Spain",
"Venezuela" = "Venezuela",
"Detrás de ti" = NA,
"Toledo" = "Toledo, Spain",
"Cuenca" = "Cuenca, Spain",
"Malaga, Spain" = "Málaga, Spain",
"Santander, Spain" = "Santander, Spain",
"Cadiz, Spain" = "Cádiz, Spain",
"Madrid - Plymouth" = "Madrid, Spain",
"Santiago de Compostela, Spain" = "Santiago de Compostela, Spain",
"Gijón, España" = "Gijón, Spain",
"Jaen, Spain" = "Jaén, Spain",
"Málaga" = "Málaga, Spain",
"Albacete, Spain" = "Albacete, Spain",
"Santa Cruz de Tenerife-Madrid" = "Santa Cruz de Tenerife, Spain",
"Móstoles, España" = "Móstoles, Spain",
"Lleida, España" = "Lleida, Spain",
"Lisboa, Portugal" = "Lisbon, Portugal",
"Huesca, España" = "Huesca, Spain",
"Cádiz, España" = "Cádiz, Spain",
"Extremadura, España" = "Extremadura, Spain",
"Ávila, España" = "Ávila, Spain",
"Santa cruz de tenerife, españa" = "Santa Cruz de Tenerife, Spain",
"Toledo, Spain" = "Toledo, Spain",
"Getafe, Spain" = "Getafe, Spain",
"Valencia, España" = "Valencia, Spain"
)
user_location$user_reported_location[is.na(user_location$user_reported_location)] <- "NA"
# Use the mapping to standardize the locations in the vector
user_location$user_reported_location <- location_map[user_location$user_reported_location]
final_nodes <- merge(x = aggregated_stats, y = user_location, by = "userid", all.x = TRUE)
final_nodes <- merge(x = final_nodes, y = user_follower, by = "userid", all.x = TRUE)
final_nodes <- merge(x = final_nodes, y = user_following, by = "userid", all.x = TRUE)
final_nodes <- merge(x = final_nodes, y = user_acc_creation, by = "userid", all.x = TRUE)
final_nodes <- merge(x = final_nodes, y = user_acc_language, by = "userid", all.x = TRUE)
final_nodes <- merge(x = final_nodes, y = user_tweet_language, by = "userid", all.x = TRUE)
final_nodes <- merge(x = final_nodes, y = user_mode_hashtags, by = "userid", all.x = TRUE)
final_nodes
reply_network <- na.omit(subset(df_raw, select=c(userid, in_reply_to_userid)))
reply_network <- subset(reply_network, in_reply_to_userid %in% users)
retweet_network <- na.omit(subset(df_raw, select=c(userid, retweet_userid)))
retweet_network <- subset(retweet_network, retweet_userid %in% users)
reply_network
retweet_network
# You can get summary statistics of the follower count
summary(final_nodes$follower_count)
final_nodes$follower_count <- as.numeric(final_nodes$follower_count)
hist(final_nodes$follower_count,
main = "Histogram of Follower Counts",
xlab = "Follower Count",
ylab = "Frequency",
breaks = 50,
col = "lightblue",
border = "white")
class(final_nodes$follower_count)
category_counts <- table(final_nodes$hashtag_category)
category_counts
# Create a bar plot
barplot(category_counts, main = "Distribution of Hashtag Categories", xlab = "Hashtag Categories", ylab = "Frequency", las = 2, col = "lightblue")
colnames(reply_network) <- c("from", "to")
colnames(retweet_network) <- c("from", "to")
edges <- rbind(reply_network, retweet_network)
engagement_graph <- snafun::to_igraph(edges, bipartite = FALSE, vertices = final_nodes)
snafun::g_summary(engagement_graph)
# Remove self-loops in the igraph object
engagement_no_loops <- igraph::simplify(engagement_graph, remove.loops = TRUE, remove.multiple = FALSE)
# Remove isolates
engagement_no_loops_isolates <- snafun::remove_isolates(engagement_no_loops)
# Convert back to a snafun network
net <- snafun::to_network(engagement_no_loops_isolates)
# Summarize the updated network
snafun::g_summary(net)
network::plot.network(net,
main = "Network Plot",
vertex.cex = 1.5,        # Size of the nodes
vertex.col = "skyblue",  # Node color
edge.col = "gray",)       # Edge color
# Assign `userid` as the vertex name for matching
network::set.vertex.attribute(net, "userid", value = final_nodes$userid)
# Set other vertex attributes
network::set.vertex.attribute(net, "user_reported_location", value = final_nodes$user_reported_location)
network::set.vertex.attribute(net, "follower_count", value = final_nodes$follower_count)
network::set.vertex.attribute(net, "following_count", value = final_nodes$following_count)
network::set.vertex.attribute(net, "account_language", value = final_nodes$account_language)
network::set.vertex.attribute(net, "hashtag_category", value = final_nodes$hashtag_category)
network::set.vertex.attribute(net, "hashtags", value = final_nodes$hashtags)
m0 <- ergm::ergm(net ~ edges)
summary(m0)
net
(user_mode_hashtags)
snafun::extract_all_vertex_attributes(net)
# Model with edges and exogenous terz
m1 <- ergm::ergm(net ~ edges + nodematch("hashtag_category"))
summary(m1)
m2 <- ergm::ergm(net ~ edges + nodematch("hashtag_category") + nodeicov("follower_count"))
summary(m2)
# Model with edges and mutual good!
m3 <- ergm::ergm(net ~ edges + mutual + nodematch("hashtag_category") + nodeicov("follower_count"),
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 10,
parallel.type = "PSOCK")
)
summary(m3)
#runs
final <- ergm::ergm(net ~ edges + nodematch("hashtag_category") + nodeicov("follower_count") + mutual + odegree(1) + transitive,
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6,))
#runs
final <- ergm::ergm(net ~ edges + nodematch("hashtag_category") + nodeicov("follower_count") + mutual + odegree(1) + transitive,
control = ergm::control.ergm(
MCMC.samplesize = 5000,
MCMC.burnin = 1000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + nodematch("hashtag_category") + nodeicov("follower_count") + mutual + odegree(1) + transitive,
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + nodematch("hashtag_category") + nodeicov("follower_count") + mutual + odegree(1) + transitive,
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + nodematch("hashtag_category") + nodeicov("like_count") + mutual + odegree(1) + transitive,
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + nodematch("hashtag_category") + nodeicov("like_count") + mutual + transitive,
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + mutual + transitive,
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + mutual + + gwesp(decay = 0.5),
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + mutual + gwesp(decay = 0.5),
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + mutual + gwesp(decay = 0.5),
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + mutual + gwesp(decay = 0.5, cutoff = 50),
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + mutual + gwesp(decay = 0.5, cutoff = 55),
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + mutual + gwesp(decay = 0.5, cutoff = 60),
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + mutual,
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
ergm::search.ergmTerms(net=net)
#runs
final <- ergm::ergm(net ~ edges + transitive,
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + idegree1.5,
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + smalldiff("quote_count"),
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + smalldiff("quote_count", cutoff = 30),
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + simmelian,
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + ostar(10),
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + dyadcov(net),
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + receiver,
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
#runs
final <- ergm::ergm(net ~ edges + transitive,
control = ergm::control.ergm(
MCMC.samplesize = 15000,
MCMC.burnin = 5000,
MCMLE.maxit = 20,
parallel = 6))
